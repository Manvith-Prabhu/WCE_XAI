{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing necessary libraries and data"
      ],
      "metadata": {
        "id": "OJsrll0lujtZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKmP2GHxpChB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "import os\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQzT3LE4KhaC"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UV2yUggNpjTF"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "# Provide the path to your zip file and the directory where you want to unzip its contents\n",
        "zip_file_path = '/content/drive/MyDrive/DatsetForUse.zip'  # Update with your file path\n",
        "extracted_dir_path = '/content/B_vs_NB/'  # Update with your desired directory\n",
        "\n",
        "os.makedirs(extracted_dir_path, exist_ok=True)\n",
        "\n",
        "# Extract the contents of the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_dir_path)\n",
        "\n",
        "# List the extracted files and directories\n",
        "extracted_files = os.listdir(extracted_dir_path)\n",
        "print(\"Extracted files and directories:\", extracted_files)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qenzruOJpjaq"
      },
      "outputs": [],
      "source": [
        "# Specify the directory path you want to list files from\n",
        "folder_path = '/content/B_vs_NB/DatsetForUse/Images_Bleeding'  # Update with your directory path\n",
        "\n",
        "# Use os.listdir to get a list of all files and directories in the specified folder\n",
        "files_and_dirs = os.listdir(folder_path)\n",
        "\n",
        "# Filter the list to get only file paths (excluding directories)\n",
        "file_paths1 = [os.path.join(folder_path, item) for item in files_and_dirs if os.path.isfile(os.path.join(folder_path, item))]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYGHF7GEqV2m"
      },
      "outputs": [],
      "source": [
        "# Specify the directory path you want to list files from\n",
        "folder_path = '/content/B_vs_NB/DatsetForUse/Images_NonBleeding'  # Update with your directory path\n",
        "\n",
        "# Use os.listdir to get a list of all files and directories in the specified folder\n",
        "files_and_dirs = os.listdir(folder_path)\n",
        "\n",
        "# Filter the list to get only file paths (excluding directories)\n",
        "file_paths2 = [os.path.join(folder_path, item) for item in files_and_dirs if os.path.isfile(os.path.join(folder_path, item))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2aaN8Far0K0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a list of file paths and their corresponding classes\n",
        "file_paths = file_paths1 + file_paths2\n",
        "classes = ['Bleeding'] * len(file_paths1) + ['NonBleeding'] * len(file_paths2)\n",
        "\n",
        "# Create a Pandas DataFrame\n",
        "data = {'filepath': file_paths, 'Class': classes}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kU1r_WSrtiUt"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['filepath'], df['Class'], test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAi-muFzxplL"
      },
      "source": [
        "# 1) ResNET152V2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nFryr-sLaXn"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet152V2\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define the input image size\n",
        "target_size = (224, 224)\n",
        "img_channels = 3  #  RGB images\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "train_df = pd.DataFrame({'filepath': X_train, 'label': y_train})\n",
        "test_df = pd.DataFrame({'filepath': X_test, 'label': y_test})\n",
        "\n",
        "# Load the pre-trained ResNet152v2 model without the top classification layer\n",
        "base_model = ResNet152V2(input_shape=(target_size[0], target_size[1], img_channels),\n",
        "                   include_top=False,\n",
        "                   weights='imagenet')\n",
        "\n",
        "# Freeze the layers of ResNet152v2\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create an ImageDataGenerator for preprocessing and data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Rescale pixel values to [0, 1]\n",
        ")\n",
        "\n",
        "# Load and preprocess training data\n",
        "train_generator = datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='filepath',\n",
        "    y_col='label',\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True  # Shuffle the training data\n",
        ")\n",
        "\n",
        "# Load and preprocess validation data\n",
        "test_generator = datagen.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='filepath',\n",
        "    y_col='label',\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False  # Do not shuffle the validation data\n",
        ")\n",
        "\n",
        "# Create the model by adding additional layers for classification\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model and specify loss, optimizer, and metrics as needed\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=test_generator\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "evaluation = model.evaluate(test_generator)\n",
        "print(\"Evaluation Loss:\", evaluation[0])\n",
        "print(\"Evaluation Accuracy:\", evaluation[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6OgaBzgbst_"
      },
      "outputs": [],
      "source": [
        "model.save('Wce_resnet.h5') #save the model\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_qf35qG40rY"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Assuming you have already trained your model and obtained predictions\n",
        "predictions = model.predict(test_generator)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "true_labels = test_generator.classes\n",
        "\n",
        "# Get the filenames of test images\n",
        "filepaths = test_generator.filepaths\n",
        "\n",
        "# Initialize lists to store misclassified filepaths\n",
        "misclassified_filepaths = []\n",
        "\n",
        "# Iterate over predictions and true labels to find misclassifications\n",
        "for i in range(len(true_labels)):\n",
        "    if predicted_labels[i] != true_labels[i]:\n",
        "        misclassified_filepaths.append(filepaths[i])\n",
        "\n",
        "# Print the misclassified filepaths\n",
        "print(\"Misclassified Filepaths:\")\n",
        "for filepath in misclassified_filepaths:\n",
        "    print(filepath)\n",
        "\n",
        "# Evaluation\n",
        "evaluation = model.evaluate(test_generator)\n",
        "print(\"Evaluation Loss:\", evaluation[0])\n",
        "print(\"Evaluation Accuracy:\", evaluation[1])\n",
        "\n",
        "# Classification Report\n",
        "report = classification_report(true_labels, predicted_labels)\n",
        "print(\"Classification Report:\\n\", report)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FWJCI3qr9Bp"
      },
      "source": [
        "# 2) MobileNETv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4CUN8ePr_QM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define the input image size\n",
        "target_size = (224, 224)\n",
        "img_channels = 3  # RGB images\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "train_df = pd.DataFrame({'filepath': X_train, 'label': y_train})\n",
        "test_df = pd.DataFrame({'filepath': X_test, 'label': y_test})\n",
        "\n",
        "# Load the pre-trained MobileNETv2 model without the top classification layer\n",
        "base_model = MobileNetV2(input_shape=(target_size[0], target_size[1], img_channels),\n",
        "                   include_top=False,\n",
        "                   weights='imagenet')\n",
        "\n",
        "# Freeze the layers of MobileNETv2\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create an ImageDataGenerator for preprocessing and data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Rescale pixel values to [0, 1]\n",
        ")\n",
        "\n",
        "# Load and preprocess training data\n",
        "train_generator = datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='filepath',\n",
        "    y_col='label',\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True  # Shuffle the training data\n",
        ")\n",
        "\n",
        "# Load and preprocess validation data\n",
        "test_generator = datagen.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='filepath',\n",
        "    y_col='label',\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False  # Do not shuffle the validation data\n",
        ")\n",
        "\n",
        "# Create the model by adding additional layers for classification\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model and specify loss, optimizer, and metrics as needed\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=test_generator\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "evaluation = model.evaluate(test_generator)\n",
        "print(\"Evaluation Loss:\", evaluation[0])\n",
        "print(\"Evaluation Accuracy:\", evaluation[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7q2-GX3_sNeA"
      },
      "outputs": [],
      "source": [
        "model.save('Wce_mobilenet.h5')\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wD_uJ9Gp5n8N"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "# Generate predictions for the test data\n",
        "predictions = model.predict(test_generator)\n",
        "\n",
        "# Convert predictions to class labels\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get true labels\n",
        "true_classes = test_generator.classes\n",
        "\n",
        "# Get class labels\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
        "\n",
        "print(\"Classification Report:\\n\", report)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Grad-CAM on sample images"
      ],
      "metadata": {
        "id": "2ozcLqb5v2HV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oG4ui9jUb8PQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from PIL import Image\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model('Wce_resnet.h5')\n",
        "# Get the name of the last convolutional layer in the model\n",
        "last_conv_layer_name = model.layers[-5].name\n",
        "print(last_conv_layer_name)\n",
        "\n",
        "# Prepare an example image for Grad-CAM\n",
        "img_path = '/content/B_vs_NB/DatsetForUse/Images_Bleeding/img- (1255).png'  # Replace with the path to your example image\n",
        "img = mpimg.imread(img_path)\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "print(img.shape)\n",
        "\n",
        "\n",
        "grad_model = tf.keras.models.Model(\n",
        "    [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        ")\n",
        "\n",
        "target_size = (224, 224)\n",
        "img = tf.image.resize(img, target_size)\n",
        "img=np.expand_dims(img,axis=0)\n",
        "num_zeros = np.count_nonzero(img == 0)\n",
        "print(num_zeros)\n",
        "\n",
        "print(model.predict(img))\n",
        "pred_index=None\n",
        "with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "\n",
        "# This is the gradient of the output neuron (top predicted or chosen)\n",
        "# with regard to the output feature map of the last conv layer\n",
        "grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "print(grads.shape)\n",
        "num_zeros = np.count_nonzero(grads == 0)\n",
        "print(num_zeros)\n",
        "\n",
        "# This is a vector where each entry is the mean intensity of the gradient\n",
        "# over a specific feature map channel\n",
        "pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "# We multiply each channel in the feature map array\n",
        "# by \"how important this channel is\" with regard to the top predicted class\n",
        "# then sum all the channels to obtain the heatmap class activation\n",
        "last_conv_layer_output = last_conv_layer_output[0]\n",
        "heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "# For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
        "heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "heatmap=heatmap.numpy()\n",
        "\n",
        "plt.matshow(heatmap)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Superimpose the heat map on original image and save it"
      ],
      "metadata": {
        "id": "pxkXQxrbwTvN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7htVIpinQ5I"
      },
      "outputs": [],
      "source": [
        "# Load the original image\n",
        "img = keras.utils.load_img(img_path)\n",
        "img = keras.utils.img_to_array(img)\n",
        "\n",
        "# Rescale heatmap to a range 0-255\n",
        "heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "alpha = 0.4\n",
        "\n",
        "# Use jet colormap to colorize heatmap\n",
        "jet = mpl.cm.get_cmap(\"jet\")\n",
        "\n",
        "# Use RGB values of the colormap\n",
        "jet_colors = jet(np.arange(256))[:, :3]\n",
        "jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "# Create an image with RGB colorized heatmap\n",
        "jet_heatmap = keras.utils.array_to_img(jet_heatmap)\n",
        "jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "jet_heatmap = keras.utils.img_to_array(jet_heatmap)\n",
        "\n",
        "# Superimpose the heatmap on the original image\n",
        "superimposed_img = jet_heatmap * alpha + img\n",
        "superimposed_img = keras.utils.array_to_img(superimposed_img)\n",
        "\n",
        "# Save the superimposed image\n",
        "cam_path = '/content/cam.jpg'\n",
        "superimposed_img.save(cam_path)\n",
        "superimposed_img.save('/content/cam1255.pdf')\n",
        "\n",
        "# Open the image\n",
        "image = Image.open(cam_path)\n",
        "\n",
        "# Show the plot\n",
        "plt.imshow(image)\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}